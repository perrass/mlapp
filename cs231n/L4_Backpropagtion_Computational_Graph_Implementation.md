# Backpropagtion: The computational graph implementation

## Algorithms

Two assumptions:

1. The cost function can be written as an average $C = \frac 1 n \sum_x C_x$ over cost functions $C_x$ for individual training examples, $x$
2. The cost is that can be written as a function of the outputs from the neural network



## Examples



## Patterns in Backward Flow



## Practical Tricks

